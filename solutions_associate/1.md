# Exam Blue Print

130 min
65 questions
Multiple Choice

100-1000, 720 pass
Valid for 3 years
Scenario based


Create AWS Cert Account
Sign In

# Why learn and get certified

# High Level Service Overview

AWS has 3 tiers of consulting partners.  They need certain numbers of staff to partner.


        Prac Certs Assoc Certs  Prof Certs
Select  2           2           0
Advanced 4          4           3
Premier  10         10          10

Difficulty levels:

CCP
Solutions Architect Assoc
Dev Assoc
Solutions Architect Prof


# History of AWS

2004 SQS
2006 AWS
2007 180K devs on platform
2010 All Amzn on AWS
2012 Re:invent
2013: Certs
2014: 100% renewable
2015: 6Bn rev
2016 $13Bn
2017: 27Bn
2018 AI/ML Certs
2019: Alexa specialty, 10 Certs

# Regions
Use us-east-1.  N Virginia tends to go down 1/years

# Global Infra
19 Regions
57 Az

AZ = Datacenter, might be several in the same few miles.  Each has redundant power, networking and conn, housed separately

Region = geographic area, 2+ AZ

Edge location: AWS content cache, usually cloudfront.  >150 ELs.

If you need a technical contact manager, you need an enterprice support plan with $15K spend

# IAM

Manage users and their access to the console

Centralized control of Account
Shared access
Granular permissions
Identity federation (AD, SSO)
MFA
Provide temporary access to users/devices/services as needed
Password rotation policy
PCI DSS (credit cards)

Users - End users such as people
Groups = A collection of users.  Each user in the group gets group permissions
Policies = JSON for permissions
Role = Authorizations for resources, like EC2

Root account = username you first sign up with.  Has god mode permissions

IAM is Global

New users have NO permissions on create.  They are assigned AKI and SAK when first created

AKISAK are not the same as password, just programmatic access

PW/Keys only viewable once on create.

Always use MFA
Create and customize password rotation Policies

How can I get a notification about spending? Cloudwatch Billing Alarm

#S3 Simple Storage Service

Object storage across multiple devices and facilities
0B to 5B file size limit
Unlimited storage in buckets

S3 is universal namespace (because it makes a web address)

When you upload, success = 200

Objects = Files
Key (name of object)
Value (data in bytes)
Version Identity
Metadata
Subresources:
    ACL
    Torrents

How does data consistency work?

Read-after-Write for PUTS of New Objects

Eventual Consistency for overwrite puts and deletes (can take time to propagate)

Guarantees:
 99.99 Availability:
 11 9s durability

Features
Tiered storage
Lifecycle management
Versioning
Encryption
MFA delete
Secure w/ ACL and bucket Policies

s3 standard:
    stored redundantly across multiple devices and facilities
    99.99 Availability:
    11 9s durability
    designed to sustain loss of 2 facilities

s3 IA (infrequently accessed)
    lower storage, + access fee

s3 1Zone IA (sometimes Reduced Reliability Storage):
    only one AZ

s3 Intelligent Tiering
    Automatically optimizes storage

s3 Glacier
    secure, durable, low-cost data archiving
    retrieval minutes to hours, configurable

s3 deep archive
    12 hour retrieval


Charged based on:
    storage,
    requests,
    storage management pricing
    data transfer pricing
    transfer acceleration
    cross region replication

What is cross region replication?
    Upload to us-east-1, autoreplicate elsewhere

Transfer Acceleration:
    Users upload to edge locations, Amazon then propagates on their backbone.

S3 is not suitable for an OS; that would be block storage

Read S3 FAQs

# S3 security and Encryption
Buckets are private by default

Access control is done with bucket policies and ACLs
S3 buckets can be configured to create access logs which log all requests made to the bucket. This can be sent to another bucket, even one in another account.

Encrypted in transit: HTTPS via SSL/TLS
Encryption at rest: server side vs client side.
Server side:
    S3 Managed Keys (SSE-S3)
    AWS Key Management Service (KMS) Managed Keys (SSE-KMS)
    SSE w/ Customer Provided Keys (SSE=C)

Versioning:
    Stores all versions of an object (even if you delete)
    Great backup tool
    Cannot be disabled, only suspended.
    Integrates with lifecycle rules
    Can add MFA delete, which uses MFA to delete a file for another layer of security

    reuploading changes a file back to private.  Older versions are unaffected
    Deleting places a delete marker on the version stack; undelete by deleting the delete marker.

Lifecycle rules:
    automates transition between storage tiers
    can be used in conjunction with Versioning
    can be applied to current and previous versions


AWS Organizations:
    is an account management service that lets you consolidate multiple AWS accounts into an organization you centrally manage.

    Best practice is a root account with just billing, with org units below that, with accounts below them.

    AWS principle: more you use, less you pay.  Orgs roll up usage across accounts to share savings.

Advantages of consolidated billing:
    One bill per AWS acct
    Volume based pricing
    Easy to track charges and allocate costs

Organizations Best Practices
    MFA on root account
    strong complex password on root acct
    Paying account is used for billing only.  Don't deploy resources there.
    Enable/disable resources with Service Control Policies on OU or acct level

Three ways to share buckets across accts
    Using Bucket Policies and IAM (whole bucket).  Programmatic access only.
    Bucket ACLs and IAM.  Down to object level.  Programmatic access only.
    Cross-account IAM roles.  Programmatic and console access.

Cross region replication
    Requires versioning be enabled on both source and sink buckets
    CRR'd buckets get the same permissions as their parent bucket
    Adding CRR doesn't apply CRR to existing keys, only new ones.  You need to do something extra for that.
    Delete markers are not replicated
    Individual deletes don't replicate

Transfer Acceleration
    Lets people PUT onto edge locations and use ship data over AMZN backbone.  Lets you use distinct URL
    AMZN has a tool to test it

Cloudfront
    is a CDN
    Origin: source of all files the CDN will distribute.  Can be S3 bucket, EC2 instance, ELB, or Route53
    Distribution: name given to CDN (collection of edge locations)
    Cache misses populate the edge locations with a TTL, like 24-72 hours.
    Web distribution: for websites
    RTMP: media streaming. (Using Adobe Flash Media Server's RTMP)
    Edge locations are not just read only (see transfer acceleration)
    You can invalidate caches, but it costs money.  Can invalidate paths selectively, like imp/*
    Can restrict access using signed URLs (like Netflix does)
    Creating a distribution can take 15min to an hour.
    Need to disable distribution before you destroy, also takes time.

Snowball
    is a petabyte scale data transfer solution.  They ship you a huge disk.
    comes in 50 or 80 TB.
    Encrypted.
    Tamperproof
    Chain of custody/trusted platform module
    on transfer, they wipe it.
    can import/export to s3

Snowball edge:
    compute and storage.
    Can support local workloads in remote or offline locations.
    connects to existing infra using standard storage interfaces
    can cluster to form local storage tier/process on premises, so work offline

Snowmobile:
    transfer up to 100PB.
    It's a tractor trailer truck

Storage Gateway: Is on sysops exam, might not be on solutions assoc
    Service that connects on software appliance with cloud-based storage for integration between on-prem IT and AWS storage infra. Replicates data into AWS.

    Downloadable as VM image you install on host in datacenter.  Supports VMWare ESXi or Microsfot Hyper-V.  Once installed and associated with your account w/ activation, use the console to create storage gateway option.

    3 flavors:
        File gateway (NFS or SMB) (for storing files_)
        Volume Gateway (iSCSI) (for storing copies of drives)
            Stored Volumes/Cached Volumes
        Take gateway
            virtual tape library.

    File gateway
        Files stored on S3, accessed through Network File System mount point.  Ownership, permission, and timestamps are durably stored in S3 in the user-metadata of the object associated with the file.  Once objects are on S3, they can be managed as native s3 objects, and buck policies apply.

    Volume gateway
        gives applications access to iSCSI protocol.  Data written to these volumes can be asynchronously backed up as point-in-time snapshots of volumves, stored as EBS snapshots.  Snapshots are incremental backups that only capture changed blocks.  All snapshot storage is compressed.

        Stored volumes: primary data stored locally with async backups to AWS.  Low latency access to entire dataset with offsite backups.  Create storage volumes and mount them as iSCSI devices from on-prem application servers.  Data written to stored volumes is stored on on-prem storage hardware.  Async backups to S3 in the form of EBS snapshots.  1Gb-16TB size for stored volumes.

    Cached volumes:
        S3 is primary datastore, frequently accessed data retained locally in storage gateway.  Minimize need to scale on-prem storage infra, still provide low-lat access to frequently accessed data.  Create storage volumes up to 32 TiB and attach as iSCSI devices from on-prem app servers.  Gateway stores data written to volumes on s3 and retains recently read data in on-prem SG cache and upload buffer storage.  1Gb-32TB size.

    Tape Gateway:
        get rid of tapes.  Durable, cost-effective, archive.  VTL interface allows using existing tape-based backup application infra to store data on virtual tape cartridges created on gateway.  Each tape gateway is preconfigd with media changer and tape drives, which are available to existing apps as iSCSI devices.  Add tape cartridges as you need to archive data.  Supported by NetBackup, BackupExec, Veeam, etc.

Athena vs Macie (popular exam topic)

    Athena: query s3 data via SQL
    Serverless, pay per query/TB scanned
    No need for ETL
    Works directly on S3

    Use cases:
        query log files
        generate biz reports on data in s3
        Analyse AWS cost and usage reports
        Run queries on clickstream data

PII:
    used to establish ID.

Macie:
    Security service that uses ML to discover and ID PII in S3.
    Works directly on data stored in s3
    Can analyze CloudTrail logs
    Good for PCI-DSS and preventing ID theft
    Dashboards, reporting, alerts.

S3 descending cost:
    Standard
    IA
    Intelligent Tiering
    One zone IA
    Glacier
    Glacier Deep Archive
